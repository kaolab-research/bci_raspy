# training you want to run:
python -m SJtools.copilot.train -action vx vy alpha -alpha=1 -obs_heatmap 11 -obs_heatmap_option com df0.99 -obs hold vel acc time -showSoftmax -holdtime=1.0 -softmax_type=two_peak -reward_type=exp_dist -timesteps=1200000 -model=PPO -extra_targets_yaml=grid-16.yaml
python -m SJtools.copilot.train -action vx vy alpha -alpha=1 -obs_heatmap 11 -obs_heatmap_option bcc df0.99 -obs hold vel acc -showSoftmax -holdtime=1.0 -softmax_type=two_peak -reward_type=exp_dist -timesteps=1200000 -model=PPO -extra_targets_yaml=grid-16.yaml -no_wandb
python -m SJtools.copilot.train -action vx vy alpha -alpha=1 -obs_heatmap 11 -obs_heatmap_option bcc com df0.99 -obs hold vel acc -showSoftmax -holdtime=1.0 -softmax_type=two_peak -reward_type=exp_dist -timesteps=1200000 -model=PPO -extra_targets_yaml=grid-16.yaml 
python -m SJtools.copilot.train -action vx vy alpha -alpha=1 -obs_heatmap 11 -obs_heatmap_option bcc com df0.99 -obs hold vel acc time -showSoftmax -holdtime=1.0 -softmax_type=two_peak -reward_type=exp_dist -timesteps=1200000 -model=PPO -extra_targets_yaml=grid-16.yaml 
python -m SJtools.copilot.train -action vx vy alpha -alpha=1 -obs_heatmap 11 -obs_heatmap_option bcc df0.99 only -obs hold vel acc -showSoftmax -holdtime=1.0 -softmax_type=two_peak -reward_type=exp_dist -timesteps=1200000 -model=PPO -extra_targets_yaml=grid-16.yaml 
python -m SJtools.copilot.train -action vx vy alpha -alpha=1 -obs_heatmap 11 -obs_heatmap_option bcc com df0.99 only -obs hold vel acc -showSoftmax -holdtime=1.0 -softmax_type=two_peak -reward_type=exp_dist -timesteps=1200000 -model=PPO -extra_targets_yaml=grid-16.yaml 

# reference
python -m SJtools.copilot.train -model=PPO -alpha=0.0 -extra_targets_yaml=dir-8-close.yaml   -center_out_back -holdtime=2.0 -stillCS=0.0 -timesteps=12000  -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -history 5 20 pos -historyReset last -velReplaceSoftmax -obs hold targetCenter -no_wandb -reward_type=copilotContribution.yaml -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=STANDARD8_0.7 #DONE STANDARD8_0.7 93 96 time = 251.50 dist = 1.04 

# Temperature = 1
python -m SJtools.copilot.train -model=PPO -action chargeTargets -action_param temperature 1 -holdtime=2.0 -stillCS=0.0 -timesteps=1200000 -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -velReplaceSoftmax -no_wandb -reward_type=baseLinDist.yaml -center_out_back -history 5 20 pos -historyReset last -extra_targets_yaml=dir-8-close.yaml -policy_param_p 64 64 64 -policy_param_v 64 64 64 -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=T8B_temperature1_0.7_1 #DONE T8B_temperature1_0.7_1 92 93 time = 208.18 dist = 0.79 
python -m SJtools.copilot.train -model=PPO -action chargeTargets -action_param temperature 1 -holdtime=2.0 -stillCS=0.0 -timesteps=1200000 -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -velReplaceSoftmax -no_wandb -reward_type=baseLinDist.yaml -center_out_back -history 5 20 pos -historyReset last -extra_targets_yaml=dir-8-close.yaml -policy_param_p 64 64 64 -policy_param_v 64 64 64 -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=T8B_temperature1_0.7_2 #DONE T8B_temperature1_0.7_2 88 93 time = 208.91 dist = 0.68 
python -m SJtools.copilot.train -model=PPO -action chargeTargets -action_param temperature 1 -holdtime=2.0 -stillCS=0.0 -timesteps=1200000 -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -velReplaceSoftmax -no_wandb -reward_type=baseLinDist.yaml -center_out_back -history 5 20 pos -historyReset last -extra_targets_yaml=dir-8-close.yaml -policy_param_p 64 64 64 -policy_param_v 64 64 64 -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=T8B_temperature1_0.7_3 #DONE T8B_temperature1_0.7_3 94 91 time = 218.52 dist = 0.71 # ** uses center expressively (harder to escape edge)
python -m SJtools.copilot.train -model=PPO -action chargeTargets -action_param temperature 1 -holdtime=2.0 -stillCS=0.0 -timesteps=1200000 -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -velReplaceSoftmax -no_wandb -reward_type=baseLinDist.yaml -center_out_back -history 5 20 pos -historyReset last -extra_targets_yaml=dir-8-close.yaml -policy_param_p 64 64 64 -policy_param_v 64 64 64 -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=T8B_temperature1_0.7_4 #DONE T8B_temperature1_0.7_4 94 91 time = 203.93 dist = 0.74 

# Temperature - 0.2 / 1.5
python -m SJtools.copilot.train -model=PPO -action chargeTargets -action_param temperature 0.5 -holdtime=2.0 -stillCS=0.0 -timesteps=1200000 -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -velReplaceSoftmax -no_wandb -reward_type=baseLinDist.yaml -center_out_back -history 5 20 pos -historyReset last -extra_targets_yaml=dir-8-close.yaml -policy_param_p 64 64 64 -policy_param_v 64 64 64 -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=T8B_temperature0.5_0.7 #DONE T8B_temperature0.5_0.7 85 90 time = 218.30 dist = 1.31 
python -m SJtools.copilot.train -model=PPO -action chargeTargets -action_param temperature 1.5 -holdtime=2.0 -stillCS=0.0 -timesteps=1200000 -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -velReplaceSoftmax -no_wandb -reward_type=baseLinDist.yaml -center_out_back -history 5 20 pos -historyReset last -extra_targets_yaml=dir-8-close.yaml -policy_param_p 64 64 64 -policy_param_v 64 64 64 -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=T8B_temperature1.5_0.7 #DONE T8B_temperature1.5_0.7 90 86 time = 243.28 dist = 0.67 


# K = 0.1 / 0.5
python -m SJtools.copilot.train -model=PPO -action chargeTargets -action_param temperature 1 K 0.3 -holdtime=2.0 -stillCS=0.0 -timesteps=1200000 -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -velReplaceSoftmax -no_wandb -reward_type=baseLinDist.yaml -center_out_back -history 5 20 pos -historyReset last -extra_targets_yaml=dir-8-close.yaml -policy_param_p 64 64 64 -policy_param_v 64 64 64 -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=T8B_K0.1_0.7 #DONE T8B_K0.1_0.7 90 95 time = 236.07 dist = 0.82 
python -m SJtools.copilot.train -model=PPO -action chargeTargets -action_param temperature 1 K 0.5 -holdtime=2.0 -stillCS=0.0 -timesteps=1200000 -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -velReplaceSoftmax -no_wandb -reward_type=baseLinDist.yaml -center_out_back -history 5 20 pos -historyReset last -extra_targets_yaml=dir-8-close.yaml -policy_param_p 64 64 64 -policy_param_v 64 64 64 -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=T8B_K0.5_0.7 #DONE T8B_K0.5_0.7 96 97 time = 211.32 dist = 0.71 # ** slow and steady accurate

# LSTM
python -m SJtools.copilot.train -model=RecurrentPPO -n_steps=8192 -batch_size=512 -action chargeTargets -action_param temperature 1 -obs targetEnd -holdtime=2.0 -stillCS=0.0 -timesteps=1200000 -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -velReplaceSoftmax    -no_wandb -reward_type=baseLinDistDecay.yaml -center_out_back -extra_targets_yaml=dir-8-close.yaml -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=T8B_LSTM2_truedecay_0.7_1 #DONE T8B_LSTM2_truedecay_0.7_1 89 95 time = 199.40 dist = 1.03 
python -m SJtools.copilot.train -model=RecurrentPPO -n_steps=8192 -batch_size=512 -action chargeTargets -action_param temperature 1 -obs targetEnd -holdtime=2.0 -stillCS=0.0 -timesteps=1200000 -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -velReplaceSoftmax    -no_wandb -reward_type=baseLinDistDecay.yaml -center_out_back -extra_targets_yaml=dir-8-close.yaml -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=T8B_LSTM2_truedecay_0.7_2 #DONE T8B_LSTM2_truedecay_0.7_2 93 92 time = 204.63 dist = 1.19 
python -m SJtools.copilot.train -model=RecurrentPPO -n_steps=8192 -batch_size=512 -action chargeTargets -action_param temperature 1 -obs targetEnd -holdtime=2.0 -stillCS=0.0 -timesteps=1200000 -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -velReplaceSoftmax    -no_wandb -reward_type=baseLinDistDecay.yaml -center_out_back -extra_targets_yaml=dir-8-close.yaml -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=T8B_LSTM2_truedecay_0.7_3 #DONE T8B_LSTM2_truedecay_0.7_3 91 94 time = 199.70 dist = 1.02 # ** does the job farily well (still escaping is not easiest but stil better)
python -m SJtools.copilot.train -model=RecurrentPPO -n_steps=8192 -batch_size=512 -action chargeTargets -action_param temperature 1 -obs targetEnd -holdtime=2.0 -stillCS=0.0 -timesteps=1200000 -lr_scheduler=constant -n_steps=2048 -softmax_type=normal_target -velReplaceSoftmax    -no_wandb -reward_type=baseLinDistDecay.yaml -center_out_back -extra_targets_yaml=dir-8-close.yaml -filePath=./SJtools/copilot/runs/24-02-18_close_charge/ -fileName=T8B_LSTM2_truedecay_0.7_4 #DONE T8B_LSTM2_truedecay_0.7_4 87 88 time = 227.83 dist = 1.01 


# training best 4 direction
# brisk deluge (90% + center reward 100)
python -m SJtools.copilot.train -model=PPO -alpha=1 -holdtime=2.0 -reward_type=lin_dist -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=complex -stillCS=0.3 -obs hold -no_wandb
python -m SJtools.copilot.train -model=PPO -alpha=1 -holdtime=2.0 -reward_type=exp_angle -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=complex -stillCS=0.3 -obs hold -no_wandb

# sparkling feather (90% + center reward 100)
python -m SJtools.copilot.train -model=PPO -alpha=1 -holdtime=2.0 -reward_type=lin_dist -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -no_wandb
python -m SJtools.copilot.train -model=PPO -alpha=1 -holdtime=2.0 -reward_type=lin_dist -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -no_wandb -obs_heatmap 10 -obs_heatmap_option com df0.99 -no_wandb
python -m SJtools.copilot.train -model=PPO -alpha=1 -holdtime=2.0 -reward_type=lin_dist -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -no_wandb -obs_heatmap 10 -obs_heatmap_option bcc df0.99 -no_wandb
python -m SJtools.copilot.train -model=PPO -alpha=1 -holdtime=2.0 -reward_type=lin_dist -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -no_wandb -obs_heatmap 10 -obs_heatmap_option com df0.99 only -no_wandb 
python -m SJtools.copilot.train -model=PPO -alpha=1 -holdtime=2.0 -reward_type=lin_dist -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -no_wandb -obs_heatmap 10 -obs_heatmap_option bcc df0.99 only -no_wandb 

# atomic music - 4 direction
python -m SJtools.copilot.train -model=PPO -holdtime=2.0 -reward_type=exp_angle -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -obs_heatmap 10 -obs hold vel acc -history 3 10 -alpha=1.0 -no_wandb # atomic music
python -m SJtools.copilot.train -model=PPO -holdtime=2.0 -reward_type=exp_angle -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -obs_heatmap 10 -obs_heatmap_option com df0.99 -obs hold vel acc -history 3 10 -alpha=1.0 -no_wandb
python -m SJtools.copilot.train -model=PPO -holdtime=2.0 -reward_type=exp_angle -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -obs_heatmap 10 -obs_heatmap_option bcc -obs hold vel acc -history 3 10 -alpha=1.0 -no_wandb
python -m SJtools.copilot.train -model=PPO -holdtime=2.0 -reward_type=exp_angle -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -obs_heatmap 10 -obs_heatmap_option bcc com df0.99 -obs hold vel acc -history 3 10 -alpha=1.0 -no_wandb
python -m SJtools.copilot.train -model=PPO -holdtime=2.0 -reward_type=exp_angle -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -obs_heatmap 10 -obs_heatmap_option bcc com df0.99 -obs hold vel acc time -history 3 10 -alpha=1.0 -no_wandb

# atomic music with no acc - 4 direction
python -m SJtools.copilot.train -model=PPO -holdtime=2.0 -reward_type=exp_angle -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -obs_heatmap 10 -obs_heatmap_option com df0.99 -obs hold vel -history 3 10 -alpha=1.0 -no_wandb
python -m SJtools.copilot.train -model=PPO -holdtime=2.0 -reward_type=exp_angle -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -obs_heatmap 10 -obs_heatmap_option bcc -obs hold vel -history 3 10 -alpha=1.0 -no_wandb
python -m SJtools.copilot.train -model=PPO -holdtime=2.0 -reward_type=exp_angle -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -obs_heatmap 10 -obs_heatmap_option bcc com df0.99 -obs hold vel -history 3 10 -alpha=1.0 -no_wandb
python -m SJtools.copilot.train -model=PPO -holdtime=2.0 -reward_type=exp_angle -timesteps=600000 -lr_scheduler=constant -n_steps=2048 -softmax_type=two_peak -stillCS=0.0 -obs_heatmap 10 -obs_heatmap_option bcc com df0.99 -obs hold vel time -history 3 10 -alpha=1.0 -no_wand

